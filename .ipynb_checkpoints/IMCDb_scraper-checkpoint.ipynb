{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import date\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export dataframe of results with today's date\n",
    "today = date.today()\n",
    "d_today = today.strftime(\"%Y_%m_%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation for Scrape Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100df = pd.read_csv(\"output_data/Top100_Movies_2010-2021.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021]\n"
     ]
    }
   ],
   "source": [
    "# create list of years\n",
    "years = top_100df[\"Year\"].unique().tolist()\n",
    "print(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2010: [], 2011: [], 2012: [], 2013: [], 2014: [], 2015: [], 2016: [], 2017: [], 2018: [], 2019: [], 2020: [], 2021: []}\n"
     ]
    }
   ],
   "source": [
    "# use a dictionary to create multiple empty lists to store each  year's top 100 movies\n",
    "obj = {}\n",
    "for year in years:\n",
    "    obj[year] = []\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the year of movies we are scraping data for; each year is done individually for quality control\n",
    "scrape_year = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Black Panther', 'Avengers: Infinity War', 'Incredibles 2', 'Jurassic World: Fallen Kingdom', 'Deadpool 2', 'The Grinch', 'Jumanji: Welcome to the Jungle', 'Mission: Impossible - Fallout', 'Ant-Man and the Wasp', 'Solo: A Star Wars Story', 'Venom', 'A Star Is Born', 'Aquaman', 'Bohemian Rhapsody', 'A Quiet Place', 'Ralph Breaks the Internet', 'Crazy Rich Asians', 'Hotel Transylvania 3: Summer Vacation', 'Halloween', 'Fantastic Beasts: The Crimes of Grindelwald', 'The Meg', \"Ocean's Eight\", 'Ready Player One', 'The Greatest Showman', 'Mamma Mia! Here We Go Again', 'The Nun', 'Peter Rabbit', 'Creed II', 'Spider-Man: Into the Spider-Verse', 'Mary Poppins Returns', 'Star Wars: Episode VIII - The Last Jedi', 'The Equalizer 2', 'Rampage', 'A Wrinkle in Time', 'Fifty Shades Freed', 'Christopher Robin', 'I Can Only Imagine', 'Smallfoot', 'The Post', 'Night School', 'Bumblebee', 'The First Purge', 'Game Night', 'Book Club', 'The House with a Clock in Its Walls', 'Skyscraper', 'Insidious: The Last Key', 'Instant Family', 'The Mule', 'Blockers', 'Pacific Rim: Uprising', 'Tomb Raider', 'Maze Runner: The Death Cure', 'Tag', 'The Nutcracker and the Four Realms', 'A Simple Favor', 'Life of the Party', 'The Predator', 'Overboard', 'Sicario: Day of the Soldado', 'I Feel Pretty', 'BlacKkKlansman', 'The Shape of Water', 'Red Sparrow', 'Breaking In', 'Goosebumps 2: Haunted Halloween', '12 Strong', 'Den of Thieves', 'First Man', 'Hereditary', \"Tyler Perry's Acrimony\", 'Sherlock Gnomes', 'Uncle Drew', 'Widows', 'Pitch Perfect 3', 'Truth or Dare', 'Paddington 2', 'Love, Simon', 'Darkest Hour', 'The Commuter', 'The 15:17 to Paris', 'Mile 22', 'Alpha', 'Peppermint', 'Death Wish', 'The Spy Who Dumped Me', 'Annihilation', 'Green Book', 'Isle of Dogs', \"Nobody's Fool\", 'Adrift', 'Ferdinand', 'Robin Hood', 'Super Troopers 2', 'Slender Man', 'Three Billboards Outside Ebbing, Missouri', 'Coco', 'Teen Titans GO! To the Movies', 'Hostiles', 'The Hate U Give']\n"
     ]
    }
   ],
   "source": [
    "# fill dictionary with lists of the top 100 movies per year, display a sample year\n",
    "for year in obj:\n",
    "    top_100 = top_100df.loc[top_100df[\"Year\"] == year]\n",
    "    obj[year] = top_100[\"Release\"].tolist()\n",
    "print(obj[scrape_year])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Function Executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 88.0.4324\n",
      "[WDM] - Get LATEST driver version for 88.0.4324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Driver [C:\\Users\\stuhu\\.wdm\\drivers\\chromedriver\\win32\\88.0.4324.96\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "# setup splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.imcdb.org/\"\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def car_mov(titles):\n",
    "    movie_dict = {}\n",
    "    for title in titles:\n",
    "        movie_dict[title] = []\n",
    "    for title in titles:\n",
    "                \n",
    "        print(f\"Processing {title}...\")\n",
    "        \n",
    "        browser.find_by_css('input').fill(title)\n",
    "        time.sleep(1)\n",
    "        browser.find_by_value('Search').click()\n",
    "        time.sleep(5)\n",
    "    \n",
    "        html = browser.html\n",
    "        soup = bs(html, 'html.parser')\n",
    "    \n",
    "        results = soup.find_all('div', class_='ThumbnailBox')\n",
    "        if len(results) != 0:\n",
    "            good = 1\n",
    "        else:\n",
    "            good = 0\n",
    "            try:\n",
    "                browser.links.find_by_text(title).click()\n",
    "                time.sleep(5)\n",
    "            except:\n",
    "                print(\"No data for the movie.\")\n",
    "                good = 0\n",
    "                continue\n",
    "        \n",
    "        if good == 1:\n",
    "            good2 = 1\n",
    "        else:\n",
    "            html = browser.html\n",
    "            soup = bs(html, 'html.parser')\n",
    "            results = soup.find_all('div', class_='ThumbnailBox')\n",
    "            if len(results) != 0:\n",
    "                good2 = 1\n",
    "            else:\n",
    "                good2 = 0\n",
    "                print(\"Not good at all: no car data.\")\n",
    "                continue\n",
    "        \n",
    "        if good2 == 1:\n",
    "            print(\"Car data collected.\")\n",
    "            count = 0\n",
    "            for result in results:\n",
    "                try:\n",
    "                    x = result.find('span', class_='Stars')\n",
    "                    y = len(x)\n",
    "                    z = result.find('a')['href']\n",
    "                    info_string = result.text\n",
    "                    count += 1\n",
    "                    movie_dict[title].append([count, info_string, z, y])\n",
    "                except:\n",
    "                    y = 'Nan'\n",
    "                    z = result.find('a')['href']\n",
    "                    info_string = result.text\n",
    "                    count += 1\n",
    "                    movie_dict[title].append([count, info_string, z, y])\n",
    "        else:\n",
    "            pass\n",
    "    browser.quit()\n",
    "    print(\"Scraping completed.\")\n",
    "    return movie_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Black Panther...\n",
      "Car data collected.\n",
      "Processing Avengers: Infinity War...\n",
      "Car data collected.\n",
      "Processing Incredibles 2...\n",
      "Car data collected.\n",
      "Processing Jurassic World: Fallen Kingdom...\n",
      "Car data collected.\n",
      "Processing Deadpool 2...\n",
      "Car data collected.\n",
      "Processing The Grinch...\n",
      "No data for the movie.\n",
      "Processing Jumanji: Welcome to the Jungle...\n",
      "Car data collected.\n",
      "Processing Mission: Impossible - Fallout...\n",
      "Car data collected.\n",
      "Processing Ant-Man and the Wasp...\n",
      "Car data collected.\n",
      "Processing Solo: A Star Wars Story...\n",
      "No data for the movie.\n",
      "Processing Venom...\n",
      "Car data collected.\n",
      "Processing A Star Is Born...\n",
      "Car data collected.\n",
      "Processing Aquaman...\n",
      "Car data collected.\n",
      "Processing Bohemian Rhapsody...\n",
      "Car data collected.\n",
      "Processing A Quiet Place...\n",
      "Car data collected.\n",
      "Processing Ralph Breaks the Internet...\n",
      "Car data collected.\n",
      "Processing Crazy Rich Asians...\n",
      "Car data collected.\n",
      "Processing Hotel Transylvania 3: Summer Vacation...\n",
      "No data for the movie.\n",
      "Processing Halloween...\n",
      "Car data collected.\n",
      "Processing Fantastic Beasts: The Crimes of Grindelwald...\n",
      "Car data collected.\n",
      "Processing The Meg...\n",
      "Car data collected.\n",
      "Processing Ocean's Eight...\n",
      "Car data collected.\n",
      "Processing Ready Player One...\n",
      "Car data collected.\n",
      "Processing The Greatest Showman...\n",
      "No data for the movie.\n",
      "Processing Mamma Mia! Here We Go Again...\n",
      "Car data collected.\n",
      "Processing The Nun...\n",
      "Car data collected.\n",
      "Processing Peter Rabbit...\n",
      "Car data collected.\n",
      "Processing Creed II...\n",
      "Car data collected.\n",
      "Processing Spider-Man: Into the Spider-Verse...\n",
      "Car data collected.\n",
      "Processing Mary Poppins Returns...\n",
      "Car data collected.\n",
      "Processing Star Wars: Episode VIII - The Last Jedi...\n",
      "Car data collected.\n",
      "Processing The Equalizer 2...\n",
      "Car data collected.\n",
      "Processing Rampage...\n",
      "Car data collected.\n",
      "Processing A Wrinkle in Time...\n",
      "Car data collected.\n",
      "Processing Fifty Shades Freed...\n",
      "Car data collected.\n",
      "Processing Christopher Robin...\n",
      "Car data collected.\n",
      "Processing I Can Only Imagine...\n",
      "Car data collected.\n",
      "Processing Smallfoot...\n",
      "Car data collected.\n",
      "Processing The Post...\n",
      "Car data collected.\n",
      "Processing Night School...\n",
      "Car data collected.\n",
      "Processing Bumblebee...\n",
      "Car data collected.\n",
      "Processing The First Purge...\n",
      "Car data collected.\n",
      "Processing Game Night...\n",
      "Car data collected.\n",
      "Processing Book Club...\n",
      "Car data collected.\n",
      "Processing The House with a Clock in Its Walls...\n",
      "Car data collected.\n",
      "Processing Skyscraper...\n",
      "Car data collected.\n",
      "Processing Insidious: The Last Key...\n",
      "Car data collected.\n",
      "Processing Instant Family...\n",
      "Car data collected.\n",
      "Processing The Mule...\n",
      "Car data collected.\n",
      "Processing Blockers...\n",
      "Car data collected.\n",
      "Processing Pacific Rim: Uprising...\n",
      "Car data collected.\n",
      "Processing Tomb Raider...\n",
      "Car data collected.\n",
      "Processing Maze Runner: The Death Cure...\n",
      "Car data collected.\n",
      "Processing Tag...\n",
      "No data for the movie.\n",
      "Processing The Nutcracker and the Four Realms...\n",
      "No data for the movie.\n",
      "Processing A Simple Favor...\n",
      "Car data collected.\n",
      "Processing Life of the Party...\n",
      "Car data collected.\n",
      "Processing The Predator...\n",
      "Car data collected.\n",
      "Processing Overboard...\n",
      "Car data collected.\n",
      "Processing Sicario: Day of the Soldado...\n",
      "Car data collected.\n",
      "Processing I Feel Pretty...\n",
      "Car data collected.\n",
      "Processing BlacKkKlansman...\n",
      "Car data collected.\n",
      "Processing The Shape of Water...\n",
      "Car data collected.\n",
      "Processing Red Sparrow...\n",
      "Car data collected.\n",
      "Processing Breaking In...\n",
      "Car data collected.\n",
      "Processing Goosebumps 2: Haunted Halloween...\n",
      "Car data collected.\n",
      "Processing 12 Strong...\n",
      "Car data collected.\n",
      "Processing Den of Thieves...\n",
      "Car data collected.\n",
      "Processing First Man...\n",
      "Car data collected.\n",
      "Processing Hereditary...\n",
      "Car data collected.\n",
      "Processing Tyler Perry's Acrimony...\n",
      "No data for the movie.\n",
      "Processing Sherlock Gnomes...\n",
      "Car data collected.\n",
      "Processing Uncle Drew...\n",
      "Car data collected.\n",
      "Processing Widows...\n",
      "Car data collected.\n",
      "Processing Pitch Perfect 3...\n",
      "Car data collected.\n",
      "Processing Truth or Dare...\n",
      "Car data collected.\n",
      "Processing Paddington 2...\n",
      "Car data collected.\n",
      "Processing Love, Simon...\n",
      "Car data collected.\n",
      "Processing Darkest Hour...\n",
      "Car data collected.\n",
      "Processing The Commuter...\n",
      "Car data collected.\n",
      "Processing The 15:17 to Paris...\n",
      "Car data collected.\n",
      "Processing Mile 22...\n",
      "Car data collected.\n",
      "Processing Alpha...\n",
      "No data for the movie.\n",
      "Processing Peppermint...\n",
      "Car data collected.\n",
      "Processing Death Wish...\n",
      "Car data collected.\n",
      "Processing The Spy Who Dumped Me...\n",
      "Car data collected.\n",
      "Processing Annihilation...\n",
      "Car data collected.\n",
      "Processing Green Book...\n",
      "Car data collected.\n",
      "Processing Isle of Dogs...\n",
      "No data for the movie.\n",
      "Processing Nobody's Fool...\n",
      "Car data collected.\n",
      "Processing Adrift...\n",
      "Car data collected.\n",
      "Processing Ferdinand...\n",
      "Car data collected.\n",
      "Processing Robin Hood...\n",
      "Car data collected.\n",
      "Processing Super Troopers 2...\n",
      "Car data collected.\n",
      "Processing Slender Man...\n",
      "Car data collected.\n",
      "Processing Three Billboards Outside Ebbing, Missouri...\n",
      "Car data collected.\n",
      "Processing Coco...\n",
      "Car data collected.\n",
      "Processing Teen Titans GO! To the Movies...\n",
      "No data for the movie.\n",
      "Processing Hostiles...\n",
      "Car data collected.\n",
      "Processing The Hate U Give...\n",
      "Car data collected.\n",
      "Scraping completed.\n"
     ]
    }
   ],
   "source": [
    "# create our dictionary of car data\n",
    "top_year = obj[scrape_year]\n",
    "top_yearcars = car_mov(top_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verification\n",
    "print(top_yearcars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export/Import Scraped Data for backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(top_yearcars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to write to file\n"
     ]
    }
   ],
   "source": [
    "# writing dictionary to text file\n",
    "try:\n",
    "    file_dict = open(f\"top_{scrape_year}cars.txt\", 'wt')\n",
    "    file_dict.write(str(top_yearcars))\n",
    "    file_dict.close()\n",
    "except: \n",
    "    print(\"Unable to write to file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unable to write a file? Try this instead, otherwise skip this\n",
    "file_dict = open(f\"top_{scrape_year}cars.txt\", 'wt', encoding=\"utf-8\")\n",
    "file_dict.write(str(top_yearcars))\n",
    "file_dict.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dictionary from text file back\n",
    "file = open(f\"top_{scrape_year}cars.txt\", \"r\")\n",
    "contents = file.read()\n",
    "data = ast.literal_eval(contents)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Missing Data Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 88.0.4324\n",
      "[WDM] - Get LATEST driver version for 88.0.4324\n",
      "[WDM] - Driver [C:\\Users\\stuhu\\.wdm\\drivers\\chromedriver\\win32\\88.0.4324.96\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "# setup splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.imcdb.org/\"\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart Manual Scrape Here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to scrape data for a single film\n",
    "def cars_manual(movie):\n",
    "    print(f\"Processing {movie}...\")\n",
    "    missing = f\"{movie}\"\n",
    "    miss_dict = {}\n",
    "    miss_dict[missing] = []\n",
    "\n",
    "    html = browser.html\n",
    "    soup = bs(html, 'html.parser')\n",
    "    \n",
    "    results = soup.find_all('div', class_='ThumbnailBox')\n",
    "    if len(results) != 0:\n",
    "        good = 1\n",
    "    else:\n",
    "        good = 0\n",
    "        try:\n",
    "            browser.links.find_by_text(missing).click()\n",
    "            time.sleep(5)\n",
    "        except:\n",
    "            print(\"No data for the movie.\")\n",
    "            good = 0\n",
    "        \n",
    "    if good == 1:\n",
    "        good2 = 1\n",
    "    else:\n",
    "        html = browser.html\n",
    "        soup = bs(html, 'html.parser')\n",
    "        results = soup.find_all('div', class_='ThumbnailBox')\n",
    "        if len(results) != 0:\n",
    "            good2 = 1\n",
    "        else:\n",
    "            good2 = 0\n",
    "            print(\"Not good at all: no car data.\")\n",
    "\n",
    "    if good2 == 1:\n",
    "        print(\"Data collected.\")\n",
    "        count = 0\n",
    "        for result in results:\n",
    "            try:\n",
    "                x = result.find('span', class_='Stars')\n",
    "                y = len(x)\n",
    "                z = result.find('a')['href']\n",
    "                info_string = result.text\n",
    "                count += 1\n",
    "                miss_dict[missing].append([count, info_string, z, y])\n",
    "            except:\n",
    "                y = 'Nan'\n",
    "                z = result.find('a')['href']\n",
    "                info_string = result.text\n",
    "                count += 1\n",
    "                miss_dict[missing].append([count, info_string, z, y])\n",
    "    else:\n",
    "        pass\n",
    "    return miss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to delete a single film's car data from our dictionary\n",
    "def delete_data(movie):\n",
    "    # remove data if no substitute can be manually found\n",
    "    del top_yearcars[movie]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do we want to update or delete data?: delete\n",
      "Title of the movie (exact upper and lower cases):The Grinch\n",
      "Do we still have a movie to update? (yes/no): yes\n",
      "Do we want to update or delete data?: update\n",
      "Title of the movie (exact upper and lower cases):Venom\n",
      "Processing Venom...\n",
      "Data collected.\n",
      "First car: [1, '1999 Acura Integra ', 'vehicle_1136076-Acura-Integra-DC4-1999.html', 1]\n",
      "Last car: [77, '2001 Volvo S60 ', 'vehicle_1222737-Volvo-S60-2001.html', 2]\n",
      "Do we still have a movie to update? (yes/no): yes\n",
      "Do we want to update or delete data?: update\n",
      "Title of the movie (exact upper and lower cases):A Star Is Born\n",
      "Processing A Star Is Born...\n",
      "Data collected.\n",
      "First car: [1, '2014 BMW X5 [F15] ', 'vehicle_1229541-BMW-X5-F15-2014.html', 1]\n",
      "Last car: [8, 'Toyota Prius II ', 'vehicle_1229540-Toyota-Prius-NHW20.html', 2]\n",
      "Do we still have a movie to update? (yes/no): yes\n",
      "Do we want to update or delete data?: update\n",
      "Title of the movie (exact upper and lower cases):Halloween\n",
      "Processing Halloween...\n",
      "Data collected.\n",
      "First car: [1, 'Blue Bird Vision ', 'vehicle_1160953-Blue-Bird-Vision.html', 'Nan']\n",
      "Last car: [7, 'Nissan Truck ', 'vehicle_1160951-Nissan-Truck-D21.html', 'Nan']\n",
      "Do we still have a movie to update? (yes/no): yes\n",
      "Do we want to update or delete data?: update\n",
      "Title of the movie (exact upper and lower cases):Rampage\n",
      "Processing Rampage...\n",
      "Data collected.\n",
      "First car: [1, 'AM General HMMWV M1025 ', 'vehicle_1154657-AM-General-HMMWV-M1025.html', 2]\n",
      "Last car: [48, 'Yale ', 'vehicle_1154635-Yale.html', 2]\n",
      "Do we still have a movie to update? (yes/no): yes\n",
      "Do we want to update or delete data?: delete\n",
      "Title of the movie (exact upper and lower cases):A Wrinkle in Time\n",
      "Do we still have a movie to update? (yes/no): yes\n",
      "Do we want to update or delete data?: update\n",
      "Title of the movie (exact upper and lower cases):Night School\n",
      "Processing Night School...\n",
      "Data collected.\n",
      "First car: [1, '2005 Audi A4 B7 ', 'vehicle_1227973-Audi-A4-Typ-8E-2005.html', 1]\n",
      "Last car: [33, '1998 Volvo S70 ', 'vehicle_1227943-Volvo-S70-1998.html', 1]\n",
      "Do we still have a movie to update? (yes/no): yes\n",
      "Do we want to update or delete data?: update\n",
      "Title of the movie (exact upper and lower cases):Skyscraper\n",
      "Processing Skyscraper...\n",
      "Data collected.\n",
      "First car: [1, '2007 Chevrolet Suburban ', 'vehicle_1195461-Chevrolet-Suburban-GMT931-2007.html', 1]\n",
      "Last car: [33, '1993 Toyota Supra Mk.IV ', 'vehicle_1167976-Toyota-Supra-JZA80-1993.html', 1]\n",
      "Do we still have a movie to update? (yes/no): yes\n",
      "Do we want to update or delete data?: update\n",
      "Title of the movie (exact upper and lower cases):Tag\n",
      "Processing Tag...\n",
      "Data collected.\n",
      "First car: [1, '2015 Chevrolet Suburban ', 'vehicle_1167203-Chevrolet-Suburban-GMTK2YC-2015.html', 2]\n",
      "Last car: [20, 'Volkswagen Jetta A6 [Typ 5K] ', 'vehicle_1178822-Volkswagen-Jetta-Typ-5K.html', 1]\n",
      "Do we still have a movie to update? (yes/no): yes\n",
      "Do we want to update or delete data?: update\n",
      "Title of the movie (exact upper and lower cases):Overboard\n",
      "Processing Overboard...\n",
      "Data collected.\n",
      "First car: [1, '2015 Cadillac Escalade ESV ', 'vehicle_1161827-Cadillac-Escalade-ESV-2015.html', 3]\n",
      "Last car: [10, '2015 Volkswagen Golf SportWagen VII [Typ 5G] ', 'vehicle_1161829-Volkswagen-Golf-SportWagen-Typ-5G-2015.html', 1]\n",
      "Do we still have a movie to update? (yes/no): yes\n",
      "Do we want to update or delete data?: update\n",
      "Title of the movie (exact upper and lower cases):Breaking In\n",
      "Processing Breaking In...\n",
      "Data collected.\n",
      "First car: [1, '2014 Mercedes-Benz E-Klasse [W212] ', 'vehicle_1296602-Mercedes-Benz-E-Klasse-W212-2014.html', 2]\n",
      "Last car: [2, '2016 Mercedes-Benz GLE [W166] ', 'vehicle_1296601-Mercedes-Benz-GLE-W166-2016.html', 3]\n",
      "Do we still have a movie to update? (yes/no): yes\n",
      "Do we want to update or delete data?: update\n",
      "Title of the movie (exact upper and lower cases):Widows\n",
      "Processing Widows...\n",
      "Data collected.\n",
      "First car: [1, '2012 Audi A6 C7 ', 'vehicle_1230787-Audi-A6-Typ-4G-2012.html', 1]\n",
      "Last car: [71, '1998 Volvo V70 XC Cross Country ', 'vehicle_1230538-Volvo-V70-XC-Cross-Country-1998.html', 2]\n",
      "Do we still have a movie to update? (yes/no): yes\n",
      "Do we want to update or delete data?: update\n",
      "Title of the movie (exact upper and lower cases):Death Wish\n",
      "Processing Death Wish...\n",
      "Data collected.\n",
      "First car: [1, '2005 Audi A6 C6 ', 'vehicle_1364797-Audi-A6-Typ-4F-2005.html', 1]\n",
      "Last car: [63, '2012 Volkswagen Passat [NMS] ', 'vehicle_1364763-Volkswagen-Passat-NMS-2012.html', 1]\n",
      "Do we still have a movie to update? (yes/no): yes\n",
      "Do we want to update or delete data?: update\n",
      "Title of the movie (exact upper and lower cases):Nobody's Fool\n",
      "Processing Nobody's Fool...\n",
      "Data collected.\n",
      "First car: [1, '2010 Acura MDX ', 'vehicle_1231594-Acura-MDX-YD2-2010.html', 1]\n",
      "Last car: [28, '2016 Volkswagen Beetle Dune Convertible [Typ 5C] ', 'vehicle_1231593-Volkswagen-Beetle-Dune-Convertible-Typ-5C-2016.html', 1]\n",
      "Do we still have a movie to update? (yes/no): yes\n",
      "Do we want to update or delete data?: delete\n",
      "Title of the movie (exact upper and lower cases):Robin Hood\n",
      "Do we still have a movie to update? (yes/no): yes\n",
      "Do we want to update or delete data?: update\n",
      "Title of the movie (exact upper and lower cases):Coco\n",
      "Processing Coco...\n",
      "Data collected.\n",
      "First car: [1, '1942 Ford ½-Ton Pick-Up ', 'vehicle_1118598-Ford-1-2-Ton-Pick-Up-21C-1942.html', 2]\n",
      "Last car: [4, '1979 Toyota Truck ', 'vehicle_1118597-Toyota-Truck-RN30-1979.html', 1]\n",
      "Do we still have a movie to update? (yes/no): yes\n",
      "Do we want to update or delete data?: delete\n",
      "Title of the movie (exact upper and lower cases):Hostiles\n",
      "Do we still have a movie to update? (yes/no): no\n",
      "Manual updates completed.\n"
     ]
    }
   ],
   "source": [
    "# while loop to manually update or delete films that were not scraped properly\n",
    "answer = \"yes\"\n",
    "while answer == \"yes\":\n",
    "    decision = input(\"Do we want to update or delete data?: \").lower()\n",
    "    if decision == \"update\":\n",
    "        title = input(\"Title of the movie (exact upper and lower cases):\")\n",
    "        new_dict = cars_manual(title)\n",
    "        # use update method to update value of errant key/title data\n",
    "        top_yearcars.update(new_dict)\n",
    "        # verification\n",
    "        print(f\"First car: {top_yearcars[title][0]}\")\n",
    "        print(f\"Last car: {top_yearcars[title][-1]}\")\n",
    "        # outgoing exit option\n",
    "        answer = input(\"Do we still have a movie to update? (yes/no): \").lower()\n",
    "    elif decision == \"delete\":\n",
    "        title = input(\"Title of the movie (exact upper and lower cases):\")\n",
    "        delete_data(title)\n",
    "        answer = input(\"Do we still have a movie to update? (yes/no): \").lower()\n",
    "    else:\n",
    "        answer = \"no\"\n",
    "print(\"Manual updates completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Data as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top_yearcars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cars for the movie, The Grinch.\n",
      "No cars for the movie, A Wrinkle in Time.\n",
      "No cars for the movie, Robin Hood.\n",
      "No cars for the movie, Hostiles.\n"
     ]
    }
   ],
   "source": [
    "# create dataframe of data for each vehicle, with movie and movie year included\n",
    "title = []\n",
    "year = []\n",
    "auto = []\n",
    "link = []\n",
    "stars = []\n",
    "for movie in top_year:\n",
    "    try:\n",
    "        cars = top_yearcars[movie]\n",
    "        for car in cars:\n",
    "            title.append(movie)\n",
    "            year.append(scrape_year)\n",
    "            auto.append(car[1])\n",
    "            link.append(car[2])\n",
    "            stars.append(car[3])\n",
    "    except:\n",
    "        print(f\"No cars for the movie, {movie}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_year_df = pd.DataFrame({\"Release\": title, \"Year\": year, \"Car\": auto, \"url\": link, \"Stars\": stars})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release</th>\n",
       "      <th>Year</th>\n",
       "      <th>Car</th>\n",
       "      <th>url</th>\n",
       "      <th>Stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black Panther</td>\n",
       "      <td>2018</td>\n",
       "      <td>2016 Bentley Continental GTC</td>\n",
       "      <td>vehicle_1115905-Bentley-Continental-GTC-2016.html</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Black Panther</td>\n",
       "      <td>2018</td>\n",
       "      <td>2012 BMW 3 [F30]</td>\n",
       "      <td>vehicle_1140467-BMW-3-F30-2012.html</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Black Panther</td>\n",
       "      <td>2018</td>\n",
       "      <td>1998 Chevrolet Prizm</td>\n",
       "      <td>vehicle_1140476-Chevrolet-Prizm-E110-1998.html</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Black Panther</td>\n",
       "      <td>2018</td>\n",
       "      <td>2011 Chevrolet Spark</td>\n",
       "      <td>vehicle_1140466-Chevrolet-Spark-M300-2011.html</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Black Panther</td>\n",
       "      <td>2018</td>\n",
       "      <td>1992 Daewoo LeMans</td>\n",
       "      <td>vehicle_1115893-Daewoo-LeMans-1992.html</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>The Hate U Give</td>\n",
       "      <td>2018</td>\n",
       "      <td>2012 Nissan Maxima</td>\n",
       "      <td>vehicle_1227836-Nissan-Maxima-A35-2012.html</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446</th>\n",
       "      <td>The Hate U Give</td>\n",
       "      <td>2018</td>\n",
       "      <td>2000 Pontiac Bonneville</td>\n",
       "      <td>vehicle_1227839-Pontiac-Bonneville-2000.html</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>The Hate U Give</td>\n",
       "      <td>2018</td>\n",
       "      <td>2007 Pontiac Solstice GXP</td>\n",
       "      <td>vehicle_1227841-Pontiac-Solstice-GXP-GMX020-20...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2448</th>\n",
       "      <td>The Hate U Give</td>\n",
       "      <td>2018</td>\n",
       "      <td>2003 Toyota Avalon</td>\n",
       "      <td>vehicle_1227828-Toyota-Avalon-MCX20-2003.html</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2449</th>\n",
       "      <td>The Hate U Give</td>\n",
       "      <td>2018</td>\n",
       "      <td>2007 Toyota Camry</td>\n",
       "      <td>vehicle_1227838-Toyota-Camry-XV40-2007.html</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2450 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Release  Year                            Car  \\\n",
       "0       Black Panther  2018  2016 Bentley Continental GTC    \n",
       "1       Black Panther  2018              2012 BMW 3 [F30]    \n",
       "2       Black Panther  2018          1998 Chevrolet Prizm    \n",
       "3       Black Panther  2018          2011 Chevrolet Spark    \n",
       "4       Black Panther  2018            1992 Daewoo LeMans    \n",
       "...               ...   ...                            ...   \n",
       "2445  The Hate U Give  2018            2012 Nissan Maxima    \n",
       "2446  The Hate U Give  2018       2000 Pontiac Bonneville    \n",
       "2447  The Hate U Give  2018     2007 Pontiac Solstice GXP    \n",
       "2448  The Hate U Give  2018            2003 Toyota Avalon    \n",
       "2449  The Hate U Give  2018             2007 Toyota Camry    \n",
       "\n",
       "                                                    url Stars  \n",
       "0     vehicle_1115905-Bentley-Continental-GTC-2016.html     1  \n",
       "1                   vehicle_1140467-BMW-3-F30-2012.html     1  \n",
       "2        vehicle_1140476-Chevrolet-Prizm-E110-1998.html     1  \n",
       "3        vehicle_1140466-Chevrolet-Spark-M300-2011.html     1  \n",
       "4               vehicle_1115893-Daewoo-LeMans-1992.html     1  \n",
       "...                                                 ...   ...  \n",
       "2445        vehicle_1227836-Nissan-Maxima-A35-2012.html     1  \n",
       "2446       vehicle_1227839-Pontiac-Bonneville-2000.html     1  \n",
       "2447  vehicle_1227841-Pontiac-Solstice-GXP-GMX020-20...     2  \n",
       "2448      vehicle_1227828-Toyota-Avalon-MCX20-2003.html     1  \n",
       "2449        vehicle_1227838-Toyota-Camry-XV40-2007.html     3  \n",
       "\n",
       "[2450 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_year_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export as csv for use elsewhere\n",
    "top_year_df.to_csv(f\"output_data/{d_today}_{scrape_year}Cars.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
